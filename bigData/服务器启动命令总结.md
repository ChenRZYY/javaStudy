[TOP]
- Bt-Panel: http://47.105.158.112:8888/3151b57c
- server01 腾讯云1 http://118.24.233.44:8888/chenzhendong??123456  26666端口 root d521707
- server02 阿里云2 http://47.105.158.112:8888/chenzhendong??zd521707  22端口 root Zd521707@ username: j1vlz8au  password: 21a66d82
   server03 腾讯云3 49.234.89.28	22端口	root zd521707@
- 滴滴云 密码 Zd521707@


1 怎么查看日志
pandoc hive讲义.md -o hive讲义.docx 

### 1:启动Zookeeper
所有服务上都启动(三台都启动)

 进程名:QuorumPeerMain
 查看状态:bin/zkServer.sh status
```shell
 #启动服务器:
	 cd /export/servers/zookeeper-3.4.9/
	 bin/zkServer.sh start
 #启动客户端:
	 cd /export/servers/zookeeper-3.4.9/
	 bin/zkCli.sh 
 #停止:
	 cd /export/servers/zookeeper-3.4.9/
	 bin/zkServer.sh stop
```
 查看启动状态:bin/zkServer.sh status
 日志信息:/export/servers/zookeeper-3.4.9/zookeeper.out
 配置环境变量以后都可以 zkServer.sh start zkCli.sh zkServer.sh stop

### 2:启动Hadoop
	bin/hdfs namenode -format
	sbin/start-dfs.sh
	sbin/start-yarn.sh
	sbin/mr-jobhistory-daemon.sh start historyserver
  启动HDFS:	start-dfs.sh 
  启动Yarn:	start-yarn.sh 
  一次启动HDFS/Yarn  start-all.sh
  启动JobHistory:	mr-jobhistory-daemon.sh  start historyserver
	
  停止HDFS:	stop-dfs.sh 
  停止Yarn:	stop-yarn.sh 
  一次停止HDFS/Yarn  stop-all.sh
  停止JobHistory:	mr-jobhistory-daemon.sh  stop historyserver
  磁盘balance整理: start-balancer.sh -threshold 8	
	
	单独启动 namenode hadoop-daemon.sh start namenode
	单独启动 datanode hadoop-daemon.sh start datanode
	检查 hdfs 文件状态 hdfs fsck -locations

  日志:/export/servers/hadoop-2.7.5/logs
     如：hadoop-root-datanode-node03.log 
	 
  访问页面:
   http://node01:50070  #HDFS页面
   http://node01:19888  #历史页面
   http://node01:8088   #yarn页面   
### 3:Hive服务
  mysql ---> hive ---->impala 
  进程名字: 
     metastore   :RunJar
	 hiveserver2 :RunJar
  1:启动hive之必须先启动mysql
   bin/hive
   配置环境变量以后启动  hive
  2:启动beeline
    cd /export/servers/apache-hive-2.1.1-bin
	nohup bin/hive --service metastore &       
	nohup bin/hive --service hiveserver2 &
    方式1：
	 bin/beeline
	 >!connect jdbc:hive2://node03:10000
	 开启本地模式:		set hive.exec.mode.local.auto=true;
	 输入用户名和密码
	方式2： 
	   expect   beeline.exp
	
  3:当做服务启动
    1前台启动  cd /export/servers/apache-hive-2.1.1-bin/
				bin/hive --service hiveserver2
	2后台启动(当做服务启动)
	nohup bin/hive --service hiveserver2  > /dev/null 2>&1 &
	nohup hive --service hiveserver2  > /dev/null 2>&1 &
	
	3后面用客户端beeline连接hiveserver2---输入用户名和密码,用户名必须为root,密码任意.
	bin/beeline
	beeline> !connect jdbc:hive2://server02:10000

   日志:
     /export/servers/apache-hive-2.1.1-bin/nohup.out  #后台启动日志
     /tmp/root/hive.log  #普通的hive日志

###4:flume服务
```shell
bin/flume-ng agent --conf conf --conf-file conf/netcat-logger.conf --name a1 -Dflume.root.logger=INFO,console
```
### 5:sqoop服务

 cd /export/servers/sqoop-1.4.6.bin__hadoop-2.0.4-alpha
 bin/sqoop import .... #导入
 bin/sqoop export .... #导出 

6:azkaban服务
 进程名字:AzkabanWebServer ， AzkabanExecutorServer
 启动：
	 1:先启动exec-server
	  cd /export/servers/azkaban/azkaban-exec-server-0.1.0-SNAPSHOT
	  bin/start-exec.sh 
	 2:激活exec-server
	  curl -G "node03:$(<./executor.port)/executor?action=activate" && echo
	 3:启动web-server
	  cd /export/servers/azkaban/azkaban-web-server-0.1.0-SNAPSHOT
	  bin/start-web.sh 
  关闭
	  cd /export/servers/azkaban/azkaban-exec-server-0.1.0-SNAPSHOT
	  bin/shutdown-exec.sh 
	  cd /export/servers/azkaban/azkaban-web-server-0.1.0-SNAPSHOT
	  bin/shutdown-web.sh 

  日志:
  /export/servers/azkaban/azkaban-web-server-0.1.0-SNAPSHOT/webServerLog_2019-12-29+16:10:53.out

 访问页面:
   https://node03:8443

###7:impala服务
 进程名字: ps -ef | grep impala
 在启动impala之前，确保： mysql , metastore, hiveserver2 已经启动
  ~~~shell
 #启动服务器:
    node03:
		service impala-state-store start
		service impala-catalog start
		service impala-server start
	node02:
		service impala-server start
	node01:
		service impala-server start
 #启动客户端:
    impala-shell
  ~~~
 日志：
    cd /var/log/impala 
	如果catalogd服务没有启动，则查看catalogd.ERROR文件
###8:oozie服务
 进程名字:Bootstrap

```shell
# 启动:
	 cd /export/servers/oozie-4.1.0-cdh5.14.0
	 bin/oozied.sh start
# 停止:
	cd /export/servers/oozie-4.1.0-cdh5.14.0
	 bin/oozied.sh stop
```


?	 
  注意，如果提醒pid文件存在，则删除以下文件之后再启动
   rm -f /export/servers/oozie-4.1.0-cdh5.14.0/oozie-server/temp/oozie.pid
 日志:
   /export/servers/oozie-4.1.0-cdh5.14.0/logs/oozie.log
 访问页面:
   http://node03:11000

###9:Hue服务
 进程名字: ps -ef  | grep hue

```shell
# 启动:
   cd /export/servers/hue-3.9.0-cdh5.14.0
   build/env/bin/supervisor 

 # 日志：
	/export/servers/hue-3.9.0-cdh5.14.0/logs/supervisor.log
```

  访问页面：
    http://node03:8888
	
###10:mysql服务
```shell
mysql启动  /etc/init.d/mysql start
配置环境变量以后启动
 方式1：service mysqld start/status/restart
 方式2：/etc/init.d/mysqld start/status/restart

--退出mysql命令窗口 exit
--查看mysql状态 service mysql status
--停止mysql     service mysql stop
--启动mysql     service mysql start	
```
### 11:kafka
```shell
#方式一：
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-server-start.sh config/server.properties

#方式二：
cd /export/servers/kafka_2.11-0.10.0.0
nohup bin/kafka-server-start.sh config/server.properties >/root/kafka.log 2>&1 &

#停止
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-server-stop.sh

#创建topic
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-topics.sh --create --zookeeper server02:2181 --topic test4 --replication-factor 2 --partitions 1 	
 
#查看主题命令
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-topics.sh  --list --zookeeper server02:2181,server01:2181,server03:2181

#生产者生产数据
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-console-producer.sh --broker-list server01:9092,server02:9092,server03:9092 --topic test3

#消费者消费数据
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-console-consumer.sh --from-beginning --topic pyg  --zookeeper server02:2181,server01:2181,server03:2181

#描述主题
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-topics.sh --describe --zookeeper server01:2181 --topic test3

#查看topic的一些信息
bin/kafka-topics.sh --describe  --topic test --zookeeper node01:2181

#增加topic分区数
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-topics.sh --zookeeper server01:2181 --alter --topic test3 --partitions 8

#修改增加配置
cd /export/servers/kafka_2.11-0.10.0.0
bin/kafka-topics.sh --zookeeper server01:2181 --alter --topic test3 --config flush.messages=1

#删除配置
bin/kafka-topics.sh --zookeeper server01:2181 --alter --topic test3 --delete-config flush.messages

#删除topic
server.properties中配置：
delete.topic.enable=true
bin/kafka-topics.sh --zookeeper server01:2181 --delete --topic test4	
```



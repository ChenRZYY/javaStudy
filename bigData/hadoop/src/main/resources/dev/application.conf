#spark需要用到的调优参数
#设置自动广播的小表的大小限制，默认10M
spark.sql.autoBroadcastJoinThreshold="10485760"
#设置sparksql shuffle的分区数
spark.sql.shuffle.partitions="50"
#设置shuffle是否压缩
spark.shuffle.compress="true"
#设置shuffle数据拉取失败的时候，重试次数
spark.shuffle.io.maxRetries="3"
#设置shuffle数据拉取失败的时候，每次重试的时间间隔
spark.shuffle.io.retryWait="5s"
#设置广播数据是否压缩
spark.broadcast.compress="true"
#设置spark的序列化方式
spark.serializer="org.apache.spark.serializer.KryoSerializer"
#设置spark的存储与执行的内存比例
spark.memory.fraction="0.6"
#设置spark的存储的内存比例
spark.memory.storageFraction="0.5"
#设置spark core的shuffle的分区数
spark.default.parallelism="10"
#设置本地化的等待时间
spark.locality.wait="3s"
#是否开启推测机制
spark.speculation.flag="true"
#设置推测机制的启动时机
spark.speculation.multiplier="1.5"
#APPID_NAME的字典文件
appID_name="src/main/resources/dmpConf/appID_name"
#设置设备的字典文件
devicedic="src/main/resources/dmpConf/devicedic"
#设置解析经纬度的数据路径
GeoLiteCity.dat="src/main/resources/dmpConf/GeoLiteCity.dat"
#纯真数据库的名称
IP_FILE="src/main/resources/dmpConf/qqwry.dat"
#纯真数据库所处的目录
INSTALL_DIR="dmpConf"
#解析ip获取省份城市
PARSE_IP_URL="https://restapi.amap.com/v3/ip?ip=%s&key=4d3a0e8edad11b18e7e3d1219e29bf0f"
#设置master地址 kudu 地址
master_address="hadoop01:7051,hadoop02:7051,hadoop03:7051"
#设置商圈库的url
BUSINESS_AREA_URL="https://restapi.amap.com/v3/geocode/regeo?location=%s&key=4d3a0e8edad11b18e7e3d1219e29bf0f"
#app字典文件路径
APPID_NAME = "src/main/resources/dmpConf/appID_name"
#设备字典文件路径 "D:\\DMP\\dmp_class_07\\src\\main\\resources\\devicedic
DEVICE_DIC = "src/main/resources/dmpConf/devicedic"
#标签衰减系数
attenu = "0.9"
#es集群地址
es.nodes="localhost"
#端口
es.port="9200"
#是否自动创建索引
es.index.auto.create="true"
#超时时间
es.http.timeout="100m"
#衰减系数
attnu="0.9"
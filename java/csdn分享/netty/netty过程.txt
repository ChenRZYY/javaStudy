在Netty的执行线程中是没有用锁来保证同步的，并且它的执行效率非常高，那么，本文就先看一下Netty是如何设计EventLoop的，是如何执行工作的：
 EventLoopGroup bossGroup = new NioEventLoopGroup(1);
 EventLoopGroup workerGroup = new NioEventLoopGroup();

	
	父类的构造方法首先会想我们传入的线程数量进行处理，如果我们传入的线程数量是0，那么就给他们赋值一个默认的线程的数目，这个数目是cpu核数的二倍，然后继续调用父类的构造方法：
	这个方法就是创建了一个线程池的名字，毕竟一个线程池会有一个任务执行器，所以要用名字对他们进行区分：
	
	public DefaultThreadFactory(String poolName, boolean daemon, int priority, ThreadGroup threadGroup) {
	 	 
	把刚才创建的线程工厂进行保存，接下来看一下eventLoop是如何被创建的：
	children[i] = newChild(executor, args);

 -> AbstractBootstrap.bind(port)
 -> AbstractBootstrap.bind(address) 
 -> AbstractBootstrap.doBind(final SocketAddress localAddress) 
	-> AbstractBootstrap.initAndRegister----------------------------1
		-> io.netty.channel.ReflectiveChannelFactory.newChannel()---1.1实例化channel
		-> io.netty.bootstrap.AbstractBootstrap.init(Channel) ------1.2根据ServerBootStrap/BootStrap初始化channel
			-> EventLoopGroup.register------------------------------1.3.1 
			-> MultithreadEventLoopGroup.register(Channel)----------1.3.1 NioEventLoopGroup调用父类MultithreadEventLoopGroup.register
			-> SingleThreadEventLoop.register-----------------------1.3.2 next().register() 用执行器里面的真正对象NioEventLoop.register
			-> AbstractChannel.AbstractUnsafe.register--------------1.3.3 AbstractUnsafe#register初始化通道
			-> AbstractChannel.register0----------------------------1.3.4 注册,执行Event: HandlerAdded,传递Event: ChannelRegistered,判断是否传递Event: ChannelActive
			-> AbstractNioChannel.doRegister------------------------1.3.5 注册到java的Selector,未绑定事件,并且获得selectionKey,selector和channel绑定
 
	-> AbstractBootstrap.doBind0 
	-> io.netty.channel.AbstractChannel.bind(SocketAddress, ChannelPromise)--从tail(所有hand的头)开始绑定,pipeline.tail一直往上找到pipeline.head
	-> io.netty.channel.DefaultChannelPipeline.bind(SocketAddress, ChannelPromise)
	-> io.netty.channel.AbstractChannelHandlerContext.bind(SocketAddress, ChannelPromise)
	-> io.netty.channel.AbstractChannelHandlerContext.invokeBind(SocketAddress, ChannelPromise)
	-> io.netty.channel.DefaultChannelPipeline.HeadContext.bind(ChannelHandlerContext, SocketAddress, ChannelPromise)
	-> io.netty.channel.Channel.Unsafe.bind(SocketAddress, ChannelPromise)
	-> io.netty.channel.AbstractChannel.AbstractUnsafe.bind(SocketAddress, ChannelPromise)
	-> io.netty.channel.socket.nio.NioServerSocketChannel.doBind(SocketAddress)
		javaChannel().bind(localAddress, config.getBacklog()); java绑定端口
		
		
	-> SingleThreadEventExecutor.execute ---------------------------NioEventLoop是的父类,执行
	-> SingleThreadEventExecutor.startThread()
	-> SingleThreadEventExecutor.doStartThread
	-> io.netty.channel.nio.NioEventLoop.run()
		-> #3 NioEventLoop.run() // for(;;)-loop
		-> #4 NioEventLoop.select(boolean oldWakenUp)
		-> #4 SingleThreadEventExecutor.runAllTasks(long timeoutNanos)
		-> io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(Set<SelectionKey>)
		-> io.netty.channel.nio.NioEventLoop.processSelectedKey(SelectionKey, AbstractNioChannel)---unsafe.read();
		-> io.netty.channel.nio.AbstractNioMessageChannel.NioMessageUnsafe.read()
		-> io.netty.channel.socket.nio.NioServerSocketChannel.doReadMessages(List<Object>)
			-> SocketChannel ch = SocketUtils.accept(javaChannel());等待新连接
			
	1、首先是new 一个ServerBootstrap，看ServerBootstrap的源码，其构造函数中没有什么初始化工作，并且，它是继承AbstractBootstrap类，其中大多数的工作都是其完成的。
	2、绑定了两个group，这两个group，一个是用来接收到连接请求时，处理，另一个是接收到数据时，处理的工作线程。
		1. 这里是使用的NioEventLoopGroup，它继承MultithreadEventLoopGroup，
		   在这个NioEventLoopGroup初始化时，会初始化线程池、Selector、ExecutorChooser（PowerOfTwoEventExecutorChooser）、队列拒绝handler、和EventLoop。这里初始化的是NioEventLoop。
		   并初始化一定数量（可以传递参数，或者是CPU线程数*2,或者是1）的NioEventLoop（相当于是线程）
		2. 而NioEventLoop继承了SingleThreadEventLoop，单线程处理提交的所有任务。主要是初始化任务队列LinkedBlockingQueue。并设置父EventLoop为NioEventLoopGroup。
		3. 以上，NIOEventLoopGroup初始化完成
	3、调用channel方法，并设置一个class。这个channel它是AbstractBootstrap的方法，主要功能是：
		1. 创建一个Channel的生成工厂，ReflectiveChannelFactory，而这个工厂的主要方法是newChannel，生成NioServerSocketChannel，它继承自AbstractNioMessageChannel类。这个channel后面再说。
	4、 调用childHandler方法，注册一个子的Handler，这个handler，主要是对worker线程使用。这里是new了一个ChannelInitializer类，它其实是继承了ChannelInboundHandlerAdapter。
		在它的抽象方法中，实现了在ChannelPipeline上注册Handler链。pipeline后面再说。
	5、第10至16设置TCP参数
	6、最后，调用bind方法。它也是在AbstractBootstrap中实现的。
		1. 在bind中，首先对地址和端口封装成SocketAddress，然后调用doBind方法。
		2. 在doBind中，首先调用的是initAndRegister方法，顾名思义，它就是初始化和注册Selector的。
		3. 在initAndRegister方法中，首先会初始化一个channel，也就是上面提到的ReflectiveChannelFactory的newChannel方法。生成NioServerSocketChannel。
			1. 在生成Channel时，使用的是反射的方式。这里着重看一下NioServerSocketChannel的初始化工作。
				1. 初始化时，先是创建了一个Java原生NIO的ServerSocketChannel，使用的是默认的SelectorProvider，也即调用的是SelectorProvider.provider()方法。
				2. 初始化AbstractNioMessageChannel，因为它继承了AbstractNioChannel类，所以还会初始化AbstractNioChannel类，而AbstractNioChannel继承了AbstractChannel。
					下面详细介绍这几个类中初始化的信息。
					1. 首先在AbstractChannel类中，生成了一个DefaultChannelId，
					2. 创建了Unsafe类，这个类使用的是newUnsafe方法，这个方法在AbstractNioMessageChannel中实现，生成其私有内部类NioMessageUnsafe，它只有read方法。
					3. 创建了上文提到的ChannelPipeline，这里创建的是DefaultChannelPipeline，并把自己传递到其中，这里也就是NioServerSocketChannel。
						在DefaultChannelPipeline中，主要是初始化了HeadContext和TailContext，
						其中HeadContext继承了AbstractChannelHandlerContext（也就是channelRead的ctx）、ChannelOutboundHandler、ChannelInboundHandler
						TailContext继承了AbstractChannelHandlerContext、ChannelInboundHandler
						1. HeadContext的功能：
							1. 初始化时，把它当成了outbound，因为它被设置成了true。
							2. 指定AbstractNioMessageChannel的unsafe类
							3. 其它的功能，在后续的代码分析中体现。
						2. TailContext的功能：
							1. 初始化时，把它当成了inbound，因为它被设置成了true。
					
					4. 设置了接受操作：OP_ACCEPT，设置channel为非阻塞模式。
					5. 创建了一个NioServerSocketChannelConfig对象，它继承了DefaultServerSocketChannelConfig类，传递进去Java NIO的ServerSocket。
						1. 会创建一个AdaptiveRecvByteBufAllocator分配策略类。
					以上，NioServerSocketChannel初始化完成。
			2. 调用ServerBootstrap的init方法
				这个方法的主要功能是设置TCP的参数，已经在Pipeline上注册一些handler。
				1. 获取到DefaultChannelPipeline，在这个Pipeline上注册ChannelInitializer，
				2. 异步执行在Pipeline上注册了一个ServerBootstrapAcceptor类，这个是ServerBootstrap的内部类，其功能是，用来接受连接的，主要是把由boss线程转移到worker线程
					并且设置了自动读取。
			以上初始化完成后，就开始了注册的流程。
			3. 调用NioEventLoopGroup的register方法
				1. 通过当前的值%size来获取一个NioEventLoop，最后会在AbstractUnsafe的register方法，并把NioEventLoop传过去。
				2. 调用AbstractNioChannel的doRegister方法，完成channel的注册。
				3. invokeHandlerAddedIfNeeded方法完成对handler的添加，因为，每次调用Pipeline的addLast方法时，都会创建一个AddTask，这时候，调用的就是这个TAsk。
					这时候主要是调用的是在ServerBootstrap中添加的ServerBootstrapAcceptor，也就是添加调用了ChannelInitializer的initChannel方法，最后把ChannelInitializer移除。
				4. 这时候调用fireChannelRegistered方法，主要是调用HeadContext、TailContext、ServerBootstrapAcceptor等的channelRegistered方法。
				5. isActive()判断，是否是活的，也就是是否已经绑定成功。这时候还没有做绑定操作，所以是false。
			以上完成了注册。
		4. 以上完成后，就进行了doBound操作。initAndRegister方法会返回一个ChannelFuture，判断其是否isDone，如果是true，则进行doBind0操作，这时候才是真正的bound。
			1. 这个都是异步操作。主要是调用channel的bound，也即NioServerSocketChannel，不过方法在AbstractChannel类中实现，最终调用DefaultChannelPipeline的bind。
			2. 在Pipeline中，主要是调用tail类的方法，然后找到是outbound的handler也即HeadContext进行bound，然后调用unsafe的bound。
			3. 这个unsafe是NioMessageUnsafe，不过方法是在AbstractUnsafe类中实现，最终还是调用NioServerSocketChannel的doBind方法。
			以上，就完成了bound操作。
			
			
			
每个链接过来都innt吗?
约定俗成的关系(非常重要):
一个EventLoopGroup包含一个或多个EventLoop
一个EventLoop在其生命周期内只能和一个Thread绑定
所有I/O操作和事件都分配给EventLoop绑定的Thread处理
一个Channel在其生命周期内，只能注册于一个EventLoop
一个EventLoop可能被分配处理多个Channel。也就是EventLoop与Channel是1:n的关系
一个Channel上的所有ChannelHandler的事件由绑定的EventLoop中的I/O线程处理
不要阻塞Channel的I/O线程，可能会影响该EventLoop中其他Channel事件处理
EventLoop接口中只定义一个方法: parent() ----- 用于返回当前EventLoop实现的实例所属的EventLoopGroup的引用

 
每个NioSer 的父类SingleThreadEventExecutor 都存储不同的执行器(但是执行器的excute,最后都是调用的Executor),存储不同的线程,调度任务队列
	
	什么时候注册selector事件
	什么时候向selector注册accept事件
	每个连接客户端channel,都new一个pipeline,每个连接channel都用同一个channelHandle,相同设置客户端TCP相关属性childOptions和自定义属性childAttrs
	整个netty就一个执行器Executor
	客户端channel的pipeline添加childHandler
	channelContext的双向列表

创建一个 AbstractChannelHandlerContext 对象，这里说一下，ChannelHandlerContext 对象是 ChannelHandler 和 ChannelPipeline 之间的关联，每当有 ChannelHandler 添加到 Pipeline 中时，都会创建 Context。Context 的主要功能是管理他所关联的 Handler 和同一个 Pipeline 中的其他 Handler 之间的交互。
判断当前线程是否是给定的 eventLoop 线程。注意：这点很重要，Netty 线程模型的高性能取决于对于当前执行的Thread 的身份的确定。如果不在当前线程，那么就需要很多同步措施（比如加锁），上下文切换等耗费性能的操作。
	
    @Override
    public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) {
        return pipeline.bind(localAddress, promise);
    }
	
	

